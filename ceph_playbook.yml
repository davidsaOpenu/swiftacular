---
- name: Compile Ceph and Verify RGW
  hosts: storage
  gather_facts: yes

  vars:
    project_base_dir: "/home/stack/projects"
    ceph_repo_url: "https://github.com/ceph/ceph.git"
    ceph_repo_version: "main"
    ceph_src_dir: "{{ project_base_dir }}/ceph"
    ceph_build_dir: "{{ ceph_src_dir }}/build"
    ceph_conf_file: "{{ ceph_build_dir }}/ceph.conf"

    rgw_port: 8000
    s3_endpoint: "http://127.0.0.1:{{ rgw_port }}"
    s3_test_bucket: "test-bucket"
    s3_test_object: "my-ansible-object"

    submodule_update_cmd: "git submodule update --init --recursive"

  tasks:
    #####################################################################
    # Repo prep (CRB/EPEL, plus EPEL-Next for CentOS Stream)
    #####################################################################
    - name: Ensure dnf-plugins-core is present (for config-manager)
      become: yes
      ansible.builtin.package:
        name: dnf-plugins-core
        state: present
      when: ansible_facts.os_family == "RedHat"

    - name: Enable CRB (CodeReady Builder) on EL9+
      become: yes
      ansible.builtin.command: dnf -y config-manager --set-enabled crb
      changed_when: "'enabled' in (crb_enable.stderr | default('')) or crb_enable.rc == 0"
      failed_when: false
      register: crb_enable
      when: ansible_facts.os_family == "RedHat" and (ansible_facts.distribution_major_version | int) >= 9

    - name: Install EPEL (and EPEL-Next on CentOS Stream)
      become: yes
      block:
        - name: Install epel-release
          ansible.builtin.package:
            name: epel-release
            state: present
        - name: Install epel-next-release on CentOS Stream
          ansible.builtin.package:
            name: epel-next-release
            state: present
          when: ansible_facts.distribution == "CentOS Stream"
      when: ansible_facts.os_family == "RedHat"

    - name: Refresh dnf metadata
      become: yes
      ansible.builtin.command: dnf -y makecache
      changed_when: false
      failed_when: false
      when: ansible_facts.os_family == "RedHat"

    - name: Show enabled repos (for debugging)
      become: yes
      ansible.builtin.command: dnf repolist
      register: repolist
      changed_when: false
      failed_when: false

    #####################################################################
    # Build toolchain
    #####################################################################
    - name: Ensure base build packages (excluding Ninja) are installed
      become: yes
      ansible.builtin.package:
        name:
          - git
          - python3
          - gcc
          - gcc-c++
          - cmake
        state: present

    # Install Ninja with a robust fallback: try ninja-build, enable repos + retry, then try ninja
    - name: Ensure Ninja is installed (try ninja-build first)
      become: yes
      block:
        - name: Install ninja-build
          ansible.builtin.package:
            name: ninja-build
            state: present
      rescue:
        - name: Re-ensure repos & cache (in case we were missing EPEL/CRB)
          block:
            - name: Ensure dnf-plugins-core is present
              ansible.builtin.package:
                name: dnf-plugins-core
                state: present
            - name: Enable CRB again (idempotent)
              ansible.builtin.command: dnf -y config-manager --set-enabled crb
              changed_when: false
              failed_when: false
            - name: Ensure EPEL and (if Stream) EPEL-Next are present
              ansible.builtin.package:
                name: "{{ ['epel-release'] + (['epel-next-release'] if ansible_facts.distribution == 'CentOS Stream' else []) }}"
                state: present
            - name: Refresh dnf metadata again
              ansible.builtin.command: dnf -y makecache
              changed_when: false
              failed_when: false
        - name: Retry install ninja-build
          become: yes
          ansible.builtin.package:
            name: ninja-build
            state: present
          register: ninja_retry
          failed_when: false
        - name: Fallback to package 'ninja' if ninja-build still unavailable
          when: (ninja_retry is defined) and (ninja_retry.failed or ninja_retry.rc | default(1) != 0)
          ansible.builtin.package:
            name: ninja
            state: present

    - name: Create projects directory
      ansible.builtin.file:
        path: "{{ project_base_dir }}"
        state: directory
        mode: "0755"

    - name: Clone Ceph repository
      ansible.builtin.git:
        repo: "{{ ceph_repo_url }}"
        version: "{{ ceph_repo_version }}"
        dest: "{{ ceph_src_dir }}"
        force: yes

    - name: Initialize and update Git submodules (idempotent)
      ansible.builtin.command: "{{ submodule_update_cmd }}"
      args:
        chdir: "{{ ceph_src_dir }}"
      changed_when: false

    - name: Install Ceph build dependencies (script)
      become: yes
      ansible.builtin.shell: |
        set -euo pipefail
        ./install-deps.sh
      args:
        chdir: "{{ ceph_src_dir }}"

    - name: "Sanity check - CMakeLists.txt exists"
      ansible.builtin.stat:
        path: "{{ ceph_src_dir }}/CMakeLists.txt"
      register: cml

    - name: Fail if CMakeLists.txt is missing
      ansible.builtin.fail:
        msg: "No CMakeLists.txt at {{ ceph_src_dir }} â€” clone or submodules might have failed."
      when: not cml.stat.exists

    # IMPORTANT: run do_cmake.sh from repo root so it creates build/ correctly
    - name: Configure the build with CMake via do_cmake.sh (idempotent)
      ansible.builtin.shell: |
        set -euo pipefail
        ./do_cmake.sh -DWITH_RADOSGW=ON -DWITH_TESTS=OFF -DCMAKE_BUILD_TYPE=RelWithDebInfo -GNinja
      args:
        chdir: "{{ ceph_src_dir }}"
        creates: "{{ ceph_build_dir }}/build.ninja"

    - name: Compile Ceph
      ansible.builtin.shell: |
        set -euo pipefail
        ninja -C "{{ ceph_build_dir }}" -j"$(nproc)"
      register: compile_out
      changed_when: compile_out.rc == 0

    - name: Ensure core client binaries exist (rados, radosgw)
      block:
        - name: Stat rados
          ansible.builtin.stat:
            path: "{{ ceph_build_dir }}/bin/rados"
          register: rados_bin
        - name: Stat radosgw
          ansible.builtin.stat:
            path: "{{ ceph_build_dir }}/bin/radosgw"
          register: radosgw_bin
        - name: Fail if binaries missing
          ansible.builtin.fail:
            msg: "Required binaries missing: rados={{ rados_bin.stat.exists }}, radosgw={{ radosgw_bin.stat.exists }}"
          when: not rados_bin.stat.exists or not radosgw_bin.stat.exists

    #####################################################################
    # Verification (vstart + RGW + S3 smoke)
    #####################################################################
    - name: Ensure runtime tools are installed (awscli, curl)
      become: yes
      block:
        - name: Install via OS packages
          ansible.builtin.package:
            name:
              - curl
              - awscli
            state: present
      rescue:
        - name: Ensure pip is present (fallback path)
          ansible.builtin.package:
            name: python3-pip
            state: present
        - name: Install awscli via pip (fallback)
          ansible.builtin.pip:
            name: awscli
            executable: pip3

    - name: Build ceph-conf if needed (non-fatal)
      ansible.builtin.shell: |
        set -euo pipefail
        ninja -C "{{ ceph_build_dir }}" -j"$(nproc)" ceph-conf
      register: cephconf_build
      failed_when: false
      changed_when: cephconf_build.rc == 0

    - name: Start the vstart development cluster (with RGW)
      ansible.builtin.shell: |
        set -euo pipefail
        MON=1 OSD=1 MDS=0 MGR=1 RGW=1 ../src/vstart.sh -n -x --bluestore
      args:
        chdir: "{{ ceph_build_dir }}"
      register: vstart_output
      failed_when: false
      changed_when: "'done' in (vstart_output.stdout | default('')) or vstart_output.rc == 0"

    - name: Wait for cluster ready via rados df
      ansible.builtin.command: "./bin/rados -c {{ ceph_conf_file }} df"
      args:
        chdir: "{{ ceph_build_dir }}"
      register: rados_df
      until: rados_df.rc == 0
      retries: 60
      delay: 5

    - name: "Optional - ceph status (non-fatal, for logs only)"
      ansible.builtin.command: "./bin/ceph -c {{ ceph_conf_file }} status"
      args:
        chdir: "{{ ceph_build_dir }}"
      register: ceph_status_optional
      failed_when: false
      changed_when: false

    - name: Create/Update RGW demo user (uid=test)
      ansible.builtin.shell: |
        set -euo pipefail
        ./bin/radosgw-admin -c "{{ ceph_conf_file }}" user create \
          --uid=test --display-name=test --access-key=test --secret-key=test \
        || ./bin/radosgw-admin -c "{{ ceph_conf_file }}" user modify \
          --uid=test --access-key=test --secret-key=test
      args:
        chdir: "{{ ceph_build_dir }}"
      register: rgw_user
      changed_when: "'created' in (rgw_user.stdout | default('')) or 'updated' in (rgw_user.stdout | default(''))"
      failed_when: false

    - name: Wait for RGW endpoint to serve HTTP (2xx/3xx)
      ansible.builtin.shell: "curl -s -o /dev/null -w '%{http_code}' {{ s3_endpoint }}/"
      args:
        chdir: "{{ ceph_build_dir }}"
      register: rgw_health
      until: "(rgw_health.stdout | int) >= 200 and (rgw_health.stdout | int) < 400"
      retries: 40
      delay: 3

    - name: S3 operations (create bucket, put object, head-object)
      block:
        - name: Create S3 bucket (idempotent)
          ansible.builtin.shell: |
            set -euo pipefail
            aws --endpoint-url "{{ s3_endpoint }}" s3api create-bucket --bucket "{{ s3_test_bucket }}" || true
          register: s3_mkbucket
          changed_when: "'Location' in (s3_mkbucket.stdout | default(''))"
          failed_when: false

        - name: Create local test file for upload
          ansible.builtin.copy:
            content: "Ceph test successful!"
            dest: "/tmp/ceph_test_file.txt"

        - name: Upload object to S3
          ansible.builtin.shell: |
            set -euo pipefail
            aws --endpoint-url "{{ s3_endpoint }}" s3 cp /tmp/ceph_test_file.txt "s3://{{ s3_test_bucket }}/{{ s3_test_object }}"
          register: s3_put

        - name: HEAD the uploaded object to verify
          ansible.builtin.shell: |
            set -euo pipefail
            aws --endpoint-url "{{ s3_endpoint }}" s3api head-object --bucket "{{ s3_test_bucket }}" --key "{{ s3_test_object }}"
          register: s3_head
      environment:
        AWS_ACCESS_KEY_ID: "test"
        AWS_SECRET_ACCESS_KEY: "test"

    - name: Display verification summary
      ansible.builtin.debug:
        msg: |
          rados df: {{ 'PASSED' if rados_df.rc == 0 else 'FAILED' }}
          RGW HTTP code: {{ rgw_health.stdout | default('N/A') }}
          S3 upload: {{ 'PASSED' if (s3_put.rc | default(1)) == 0 else 'FAILED' }}
          S3 head-object: {{ 'PASSED' if (s3_head.rc | default(1)) == 0 else 'FAILED' }}

    #####################################################################
    # Always cleanup vstart artifacts created during verification
    #####################################################################
    - name: Stop the vstart cluster
      ansible.builtin.shell: |
        set -euo pipefail
        ../src/stop.sh || true
      args:
        chdir: "{{ ceph_build_dir }}"
      failed_when: false

    - name: Clean test artifacts
      ansible.builtin.file:
        path: "/tmp/ceph_test_file.txt"
        state: absent
      failed_when: false
